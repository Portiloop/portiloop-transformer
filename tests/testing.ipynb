{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/project/MASS/SS1_EDF/01-01-0001 Base.edf'\n",
    "PATH_real = '/project/MASS/SS1_EDF/01-01-0001 PSG.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_lib_annotations =  pyedflib.EdfReader(PATH)\n",
    "edf_lib_real =  pyedflib.EdfReader(PATH_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sleep stage annotations\n",
    "annotations = edf_lib_annotations.readAnnotations()\n",
    "# Extract the signal \n",
    "signal = edf_lib_real.readSignal(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the different values in array\n",
    "unique_values = np.unique(annotations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.00000000e+00, 3.90000000e+01, 6.90000000e+01, ...,\n",
       "       3.04590001e+04, 3.04890001e+04, 3.05190001e+04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30554.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.size / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage ?',\n",
       "       'Sleep stage R', 'Sleep stage W'], dtype='<U13')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding empty labels 9\n",
      "30549\n"
     ]
    }
   ],
   "source": [
    "curr_index = 0\n",
    "labels = []\n",
    "for annotation in np.stack(annotations).T:\n",
    "    onset, duration, label = annotation\n",
    "    # Check if we have some empty space\n",
    "    # print(f\"Before: onset: {onset}, duration: {duration}, label: {label}\")\n",
    "    onset = float(onset)\n",
    "    duration = float(duration)\n",
    "    # print(f\"After: onset: {onset}, duration: {duration}, label: {label}\")\n",
    "\n",
    "    if onset > curr_index:\n",
    "        # print(f\"Empty space between {curr_index} and {onset}\")\n",
    "        # Add empty labels\n",
    "        if int(onset - curr_index) > 0:\n",
    "            print(f\"adding empty labels {int(onset - curr_index)}\")\n",
    "            labels += ['?'] * int(onset - curr_index)\n",
    "    # Add the label\n",
    "    labels += [label.strip('Sleep stage ')] * int(duration)\n",
    "    curr_index = onset + duration\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['1', '2', '3', '?', 'R', 'W'], dtype='<U1'),\n",
       " array([ 2070, 15000,  3450,  3009,  5220,  1800]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many labels we have\n",
    "np.unique(np.array(labels), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.zeros((180, 30500))\n",
    "# Save array to csv file\n",
    "np.savetxt(\"test.csv\", array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "sum([random.randint(0, 1) for _ in range(1000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from transformiloop.src.data.pretraining import read_pretraining_dataset\n",
    "from transformiloop.src.data.spindle_trains import EquiRandomSampler, SpindleTrainDataset, read_spindle_trains_labels\n",
    "from transformiloop.src.utils.configs import initialize_config\n",
    "\n",
    "\n",
    "ds_dir = '/project/portiloop_transformer/transformiloop/dataset'\n",
    "MASS_dir = '/project/portiloop_transformer/transformiloop/dataset/MASS_preds'\n",
    "# Read all the subjects available in the dataset\n",
    "labels = read_spindle_trains_labels(ds_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling took 0.0362246036529541 seconds\n",
      "Number of spindle labels: 95264\n"
     ]
    }
   ],
   "source": [
    "config = initialize_config(\"test\")\n",
    "config['model_type'] = \"transformer\"\n",
    "config['classes'] = 2\n",
    "\n",
    "# Divide the subjects into train and test sets\n",
    "subjects = list(labels.keys())\n",
    "# random.shuffle(subjects)\n",
    "train_subjects = [subjects[0]]\n",
    "\n",
    "# Read the pretraining dataset\n",
    "data = read_pretraining_dataset(MASS_dir, patients_to_keep=train_subjects)\n",
    "\n",
    "# Create the train and test datasets\n",
    "train_dataset = SpindleTrainDataset(train_subjects, data, labels, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.unique(train_dataset.full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for index in train_dataset.spindle_labels_first:\n",
    "    if train_dataset.full_labels[index] != 2:\n",
    "        count.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(train_dataset.spindle_labels_train)\n",
    "# torch.unique(torch.tensor(count))\n",
    "count\n",
    "# train_dataset.full_labels[count[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m index ,(onset, offset, l) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(labels[train_subjects[\u001b[39m0\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39monsets\u001b[39m\u001b[39m'\u001b[39m], labels[train_subjects[\u001b[39m0\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39moffsets\u001b[39m\u001b[39m'\u001b[39m], labels[train_subjects[\u001b[39m0\u001b[39m]][\u001b[39m'\u001b[39m\u001b[39mlabels_num\u001b[39m\u001b[39m'\u001b[39m])):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mif\u001b[39;00m onset \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m count[\u001b[39m0\u001b[39;49m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m offset:\n\u001b[1;32m      3\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound \u001b[39m\u001b[39m{\u001b[39;00monset\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00moffset\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00ml\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m         \u001b[39mprint\u001b[39m(index)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for index ,(onset, offset, l) in enumerate(zip(labels[train_subjects[0]]['onsets'], labels[train_subjects[0]]['offsets'], labels[train_subjects[0]]['labels_num'])):\n",
    "    if onset <= count[0] <= offset:\n",
    "        print(f\"Found {onset} {offset} {l}\")\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[train_subjects[0]]['labels_num'][133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1446144.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1412250 / 250 * 256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "349ce3dec72c9c4811ba7909f61dd9138bbfee02ab3b29865c7ec1a0d2271283"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
